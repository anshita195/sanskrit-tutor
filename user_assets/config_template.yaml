# Sanskrit Tutor Configuration Template
# Copy this to config.yaml and customize for your setup

# =================
# MODEL CONFIGURATION
# =================

# Option 1: Local GGUF Model (Recommended for privacy)
model_path: "user_assets/models/mistral-7b-instruct-q4_k_m.gguf"  # Path to your GGUF model
gguf_local: true  # Set to true to use local GGUF model
n_ctx: 4096  # Context window size (adjust based on your model and memory)
n_gpu_layers: 0  # Number of layers to offload to GPU (0 = CPU only, 35 = full GPU for 7B model)

# Option 2: Hosted API (Requires API keys)
# model_path: null
# gguf_local: false
# Then set environment variables:
# export HF_API_KEY="hf_your_key_here"
# export OPENAI_API_KEY="sk_your_key_here"

# =================
# DATA CONFIGURATION  
# =================

# Your Sanskrit texts (REQUIRED)
passages_file: "user_assets/passages.jsonl"

# Your question-answer pairs (REQUIRED)
qa_file: "user_assets/qa_pairs.jsonl"

# Where to store the search index (generated automatically)
faiss_index_path: "data/faiss.index"

# =================
# EMBEDDING CONFIGURATION
# =================

# Embedding model for semantic search
embeddings_model: "sentence-transformers/all-mpnet-base-v2"
# Alternatives:
# "sentence-transformers/all-MiniLM-L6-v2"  # Faster, smaller
# "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # Better for Sanskrit

# =================
# RAG PARAMETERS
# =================

# Number of passages to retrieve for each question
retrieval_k: 5

# Maximum tokens to generate in responses
max_tokens: 500

# Temperature for text generation (0.0 = deterministic, 1.0 = creative)
temperature: 0.7

# =================
# OPTIONAL FEATURES
# =================

# Audio samples directory (for pronunciation practice)
audio_folder: "user_assets/audio_samples"

# =================
# API FALLBACK MODELS
# =================

# Hugging Face model to use if HF_API_KEY is set
hf_model: "mistralai/Mistral-7B-Instruct-v0.1"

# OpenAI model to use if OPENAI_API_KEY is set  
openai_model: "gpt-3.5-turbo"

# =================
# ADVANCED SETTINGS
# =================

# Batch size for embedding generation (reduce if memory issues)
embedding_batch_size: 32

# Whether to use GPU acceleration for embeddings
use_gpu_embeddings: false

# Logging level (DEBUG, INFO, WARNING, ERROR)
log_level: "INFO"
